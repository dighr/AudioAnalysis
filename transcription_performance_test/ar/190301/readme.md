## Content
This folder contains the transcription results of an arabic dataset obtained using the following API
    - Azure
    - google

## Dataset 
This dataset is obtained from the University of oxford text archive
"Arabic Speech corpus" by Nawar Halabi
http://ota.ox.ac.uk/desc/2561

## Transcription Procedure
Within the test.py script under the parent folder of this directory, there is a method named
The method takes in different parameters as described below to identify which vendor ((Google, Azure, watson) 
or the open source english transcription modal deepseech ) and which language to use.
Once this is done, an API call is made to the respective vendor to transcribe the audio using the specified language modal

### transcribe_audios(files_path, format, modal_code, type)
#### inputs
This method takes in a the following parameters:
   - files_path: the path where the audios files are located
   - format: "mp3" or "wav"
   - modal_code: any of the arabic modals supported by google, azure. The modal code for google can be obtained from 
    the following URL  https://cloud.google.com/speech-to-text/docs/languages
   - type: can be either "azure", "google", "watson", "deepspeech"
            Since "watson" and "deepspeech", don't support Arabic yet, "azure" and "google" is able to use
   
#### outputs
A csv file that contains the transcription results associated with each file is generated
This method saves the results generated by the specified modals and vendor (type) into a csv file. 
The csv file will be created after 10 transcriptions. Everytime 10 audios are transcribed, the csv file will be 
automatically saved

#### Prerequisite
- API keys for each vendor (Google, Azure, Watson) has to be correctly configured within the engine.py file of the transcription analysis folder
- An empty folder named "audio_files" have to be added to this folder. In case the format of the audio is not '.wav', 
  this folder will be used as a temporary location to automatically convert the audio files into wav
- For deepspeech, the open source modal (around 4 GB) should be downloaded and added into the parent directory of the project

## Scores
The scores were calculated by following the below procedures
   - Every actual and generated results were preprocessed before calculating their scores (implementation is under
    the method "pre_process_arabic_string" in the "test.py")
       * Each arabic sentence is converted into english chars using the buckwalter transliteration 
       * From the converted string, symbols that do not change the meaning of the sentence were removed from the file
       * Other suggested pre-processing were performed like removing extras paces were performed (Can be looked at from the implementation)
       
   - The sentence similarity results reported within each file use two different methods
      * Word Error Rate (WER): *The value shown with the csv files are 1 - WER" which identify similarity rather than error
          - The following python package was used to calculate WER: 
          - For more info about(WER): https://en.wikipedia.org/wiki/Word_error_rate 
      * Similarity Score: 
          - The scores were calculated using suggestion from the following median article
                https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50
          - The implemetation "get_similarity_scores" is under the test.py file
          - In all the expirements made, this method reported less scores than (1 - WER)
       

## Content
This folder contains the transcription results of english audios obtained by using the following APIS
 - Azure
 - Google
 - Watson
 - Deepspeech

## Dataset 
The dataset used within this expirement were taken from https://voice.mozilla.org/en/datasets
The audios associated with this "cv-valid-dev.csv" csv file were used.
This was taken from the old version that was distributed by mozilla 

## Transcription Procedure
Within the test.py script under the parent folder of this directory, there is a method named 
transcribe_audios(files_path, format, modal_code, type)
The method takes in different parameters as described below to identify which vendor ((Google, Azure, watson) 
or the open source english transcription modal deepseech ) and which language to use.
Once this is done, an API call is made to the respective vendor to transcribe the audio using the specified language modal

### transcribe_audios(files_path, format, modal_code, type)
#### inputs
This method takes in a the following parameters:
   - files_path: the path where the audios files are located
   - format: "mp3" or "wav"
   - modal_code: any of the arabic modals supported by google, azure. The modal code for google can be obtained from 
    the following URL  https://cloud.google.com/speech-to-text/docs/languages
   - type: can be either "azure", "google", "watson", "deepspeech"
   
#### outputs
A csv file that contains the transcription results associated with each file is generated
This method saves the results generated by the specified modals and vendor (type) into a csv file. 
The csv file will be created after 10 transcriptions. Everytime 10 audios are transcribed, the csv file will be 
automatically saved

#### Prerequisite
- API keys for each vendor (Google, Azure, Watson) has to be correctly configured within the engine.py file of the transcription analysis folder
- An empty folder named "audio_files" have to be added to this folder. In case the format of the audio is not '.wav', 
  this folder will be used as a temporary location to automatically convert the audio files into wav
- For deepspeech, the open source modal (around 4 GB) should be downloaded and added into the parent directory of the project


## Scores
The results reported within each file use two different methods
   - Word Error Rate (WER): *The value shown with the csv files are 1 - WER" which identify similarity rather than error
      * The following python package was used to calculate WER: 
      * For more info about(WER): https://en.wikipedia.org/wiki/Word_error_rate 
   - Similarity Score: 
      * The scores were calculated using suggestion from the following median article
                https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50
      * The implemetation "get_similarity_scores" is under the test.py file
      * In all the expirements made, this method reported less scores than (1 - WER)
       
